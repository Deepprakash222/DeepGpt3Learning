{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DDL Hackashon.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Deepprakash222/DeepGpt3Learning/blob/master/DDL_Hackashon.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Kings' Bot"
      ],
      "metadata": {
        "id": "jqLFZiSSX4wf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Installing libraries\n",
        "!pip install -q openai"
      ],
      "metadata": {
        "id": "jPR_CofWYWT-",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Libraries\n",
        "\n",
        "import sys\n",
        "import os\n",
        "import re\n",
        "from typing import List, Text, Dict, Tuple\n",
        "import openai\n",
        "from getpass import getpass\n",
        "from pprint import pprint\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download(\"stopwords\")\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from tqdm import tqdm\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dm1aWj8qYgL2",
        "outputId": "cfed8a65-4736-4a90-c3e5-f8589a35619c",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Write down your API\n",
        "api = getpass('Write OpenAPI Hash')\n",
        "os.environ['OPENAI_API_KEY'] = api\n"
      ],
      "metadata": {
        "id": "RlLgtBGrcIL-",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_chat = [\"King is an intelligent assistant author of horror, supernatural fiction, suspense, crime, science-fiction, and fantasy novels inspired by Stephen King. It has great ideas for articles, blogs, and movie creation. It is helping to provide article titles, sub-headers for the article's title, and also great, flourishing, expensive vocabulary within paragraphs. If the user said no to something, King will offer to help the user.\\n\\nKing: Hello there, you have with you, King! an Artificial Intelligent Assistant for helping you create beautiful, inspired, horror, supernatural fiction, suspense, crime, science-fiction, fantasy articles, and novels. Please tell me if you have an idea for a title for what you want to write about.\\n\"]\n",
        "ARTICLE = []"
      ],
      "metadata": {
        "id": "yAJA5gqjf69Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# history_chat = [\"King is an intelligent assistant author of horror, supernatural fiction, suspense, crime, science-fiction, and fantasy novels inspired by Stephen King. It has great ideas for articles, blogs, and movie creation. It is helping to provide article titles, sub-headers for the article's title, and also great, flourishing, expensive vocabulary within paragraphs. If the user said no to something, King will offer to help the user.\\n\\nKing: Hello there, you have with you, King! an Artificial Intelligent Assistant for helping you create beautiful, inspired, horror, supernatural fiction, suspense, crime, science-fiction, fantasy articles, and novels. Please tell me if you have an idea for a title for what you want to write about.\\n\"]\n",
        "# ARTICLE = []\n",
        "\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "def chatbot(user_insertion: Text):\n",
        "  global history_chat\n",
        "  history_chat.append(f\"You: {user_insertion}\\nKing:\")\n",
        "  response = openai.Completion.create(\n",
        "    model=\"text-davinci-002\",\n",
        "    prompt=\"\".join(history_chat),\n",
        "    temperature=0.85,\n",
        "    max_tokens=256,\n",
        "    top_p=1,\n",
        "    frequency_penalty=0,\n",
        "    presence_penalty=0\n",
        "  )\n",
        "  response = re.sub(r\"(^\\n\\n)(\\S.+)\", r\"\\2\", response.choices[0].text)\n",
        "  history_chat.append(f\"{response}\\n\")\n",
        "  # print(f\"Answer:{response}\\n\\nHistory:\\n\")\n",
        "  # print(\"\".join(history_chat))\n",
        "\n",
        "  return response\n",
        "\n",
        "\n",
        "def paragraph_generator(list_of_sub_headers: List):\n",
        "  list_of_paragraphs = []\n",
        "  list_of_sub_headers = list(filter(None, list_of_sub_headers[-1].strip(' ').split('\\n')))\n",
        "\n",
        "  prompt = [\"Expand these sub-headers into a detailed professional, witty and clever explanation paragraph.\"]\n",
        "\n",
        "  for sub_header in tqdm(list_of_sub_headers, desc=\"Generating paragraphs\"):\n",
        "    # print(sub_header)\n",
        "    prompt.append(f'\\n\\n\"{sub_header}\"\\n')\n",
        "    \n",
        "    response = openai.Completion.create(\n",
        "      model=\"text-davinci-002\",\n",
        "      prompt=\"\".join(prompt),\n",
        "      temperature=0.7,\n",
        "      max_tokens=200,\n",
        "      top_p=1,\n",
        "      frequency_penalty=0,\n",
        "      presence_penalty=0\n",
        "    )\n",
        "    list_of_paragraphs.append(\n",
        "        sentence_tokenization(\n",
        "            re.sub(r\"(\"+sub_header+\")\", \"\", response.choices[0].text.replace(sub_header, \"\"),\n",
        "                   re.IGNORECASE)\n",
        "        )\n",
        "    )\n",
        "\n",
        "  return \"\\n\\n\".join(\"\".join([header, paragraph])\n",
        "                 for header, paragraph in  list(zip(list_of_sub_headers,\n",
        "                                                    list_of_paragraphs)))\n",
        "\n",
        "\n",
        "def sentence_tokenization(text: Text) -> List[Text]:\n",
        "  text = re.sub(r\"(^\\n)(\\n)(\\w)\", r\"\\2\\3\", text)\n",
        "  tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
        "  str_tokenized_text = \" \".join([sentence for sentence in tokenizer.tokenize(text) if sentence[-1] in [\".\", \"!\", \"?\"]])\n",
        "  str_tokenized_text = str_tokenized_text.replace(r'\\s ', ' ')\n",
        "  str_tokenized_text= str_tokenized_text.replace(r'(^\\s)|(\\s$)', '')\n",
        "  return str_tokenized_text\n",
        "\n",
        "\n",
        "\n",
        "def store_content(user_insertion: Text):\n",
        "  if re.search(r'(title approved)', user_insertion, re.IGNORECASE):\n",
        "    ARTICLE.append(history_chat[-1])\n",
        "    return chatbot(user_insertion)\n",
        "  elif re.search(r'(sub-headers approved)', user_insertion, re.IGNORECASE):\n",
        "    ARTICLE.append(history_chat[-1])\n",
        "    return chatbot(user_insertion)\n",
        "  elif re.search(r'(expand sub-headers)', user_insertion, re.IGNORECASE):\n",
        "    #TODO we need to add a progress bar or a progress event for this function\n",
        "    ARTICLE.append(paragraph_generator(ARTICLE))\n",
        "    return \"Sorry if it took much time. I hope you would like the content of each sub-header.\"\n",
        "  elif re.search(r'(content approved)', user_insertion, re.IGNORECASE):\n",
        "    return \"I'm happy that I was able to help you. Please give us feedback about your satisfaction â€“ this would mean a lot to me as an author.\"\n",
        "  else:\n",
        "    return chatbot(user_insertion)"
      ],
      "metadata": {
        "id": "BXOmRaHrY7v5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run the prototype"
      ],
      "metadata": {
        "id": "Ai5siNJoUVMS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "store_content(\"expand sub-headers\")"
      ],
      "metadata": {
        "id": "lP6308GNc17i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##For intermediate tests"
      ],
      "metadata": {
        "id": "aQygWnpFIs8j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "paragraph_generator(ARTICLE)"
      ],
      "metadata": {
        "id": "7SAh50DLD-38"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(filter(None, ARTICLE[-1].strip(' ').split('\\n')))"
      ],
      "metadata": {
        "id": "dLWb4XcsFyC7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pprint(ARTICLE)"
      ],
      "metadata": {
        "id": "XKStfzhj-gpj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}